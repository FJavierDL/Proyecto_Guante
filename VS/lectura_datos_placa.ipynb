{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'predict'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[85], line 43\u001b[0m\n\u001b[0;32m     39\u001b[0m         cont\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     41\u001b[0m     \u001b[38;5;66;03m# puerto_serie.close()    # Cerrar el puerto serie\u001b[39;00m\n\u001b[1;32m---> 43\u001b[0m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[85], line 35\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28mprint\u001b[39m()\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m cont\u001b[38;5;241m<\u001b[39m\u001b[38;5;241m50\u001b[39m:\n\u001b[0;32m     32\u001b[0m     \u001b[38;5;66;03m# datos = puerto_serie.readline().decode().strip()  # Leer datos de la UART\u001b[39;00m\n\u001b[0;32m     33\u001b[0m     \u001b[38;5;66;03m# print(datos, end='\\r')\u001b[39;00m\n\u001b[1;32m---> 35\u001b[0m     prediccion \u001b[38;5;241m=\u001b[39m \u001b[43mpredice\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdatos\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     36\u001b[0m     \u001b[38;5;28mprint\u001b[39m(prediccion)\n\u001b[0;32m     38\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m0.001\u001b[39m)\n",
      "Cell \u001b[1;32mIn[85], line 20\u001b[0m, in \u001b[0;36mpredice\u001b[1;34m(datos)\u001b[0m\n\u001b[0;32m     18\u001b[0m prediccion \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     19\u001b[0m datos \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(datos)\n\u001b[1;32m---> 20\u001b[0m prediccion \u001b[38;5;241m=\u001b[39m \u001b[43mmodelo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m(datos)\n\u001b[0;32m     21\u001b[0m prediccion\u001b[38;5;241m.\u001b[39mappend(datos)\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m prediccion\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'predict'"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "import numpy as np\n",
    "import serial\n",
    "import time\n",
    "\n",
    "modelo = None  # Inicializa modelo como None\n",
    "\n",
    "def config_puerto_serie():\n",
    "    puerto_serie = serial.Serial('COM5', 115200, xonxoff=True)    # Configurar la comunicación serie\n",
    "    time.sleep(2)     # Esperar un tiempo para que la comunicación se establezca correctamente\n",
    "    return puerto_serie\n",
    "\n",
    "def carga_modelo():\n",
    "    modelo = load_model(\"modelo_3_precision_99,906_porc_sigmoid_2_neuronas_intermedia.h5\")\n",
    "    return modelo\n",
    "\n",
    "def predice(datos):\n",
    "    prediccion = []\n",
    "    datos = np.array(datos)\n",
    "    prediccion = modelo.predict(datos)\n",
    "    prediccion.append(datos)\n",
    "    return prediccion\n",
    "\n",
    "def main():\n",
    "    # puerto_serie = config_puerto_serie()\n",
    "    carga_modelo()\n",
    "    \n",
    "    datos = [0.99993896,0.01214600,-0.00439453,0.00000000]\n",
    "    cont = 0\n",
    "    print()\n",
    "    while cont<50:\n",
    "        # datos = puerto_serie.readline().decode().strip()  # Leer datos de la UART\n",
    "        # print(datos, end='\\r')\n",
    "\n",
    "        prediccion = predice(datos)\n",
    "        print(prediccion)\n",
    "\n",
    "        time.sleep(0.001)\n",
    "        cont+=1\n",
    "\n",
    "    # puerto_serie.close()    # Cerrar el puerto serie\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo cargado correctamente\n",
      "<keras.engine.sequential.Sequential object at 0x0000019C8EE53B50>\n",
      "\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 4) for input KerasTensor(type_spec=TensorSpec(shape=(None, 4), dtype=tf.float32, name='dense_72_input'), name='dense_72_input', description=\"created by layer 'dense_72_input'\"), but it was called on an input with incompatible shape (None,).\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"C:\\Users\\fraja\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training.py\", line 2137, in predict_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\fraja\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training.py\", line 2123, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\fraja\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training.py\", line 2111, in run_step  **\n        outputs = model.predict_step(data)\n    File \"C:\\Users\\fraja\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training.py\", line 2079, in predict_step\n        return self(x, training=False)\n    File \"C:\\Users\\fraja\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\fraja\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\input_spec.py\", line 250, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Exception encountered when calling layer 'sequential_44' (type Sequential).\n    \n    Input 0 of layer \"dense_72\" is incompatible with the layer: expected min_ndim=2, found ndim=1. Full shape received: (None,)\n    \n    Call arguments received by layer 'sequential_44' (type Sequential):\n      • inputs=tf.Tensor(shape=(None,), dtype=float32)\n      • training=False\n      • mask=None\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[59], line 51\u001b[0m\n\u001b[0;32m     47\u001b[0m         cont\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     49\u001b[0m     \u001b[38;5;66;03m# puerto_serie.close()    # Cerrar el puerto serie\u001b[39;00m\n\u001b[1;32m---> 51\u001b[0m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[59], line 43\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28mprint\u001b[39m()\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m cont\u001b[38;5;241m<\u001b[39m\u001b[38;5;241m50\u001b[39m:\n\u001b[0;32m     40\u001b[0m     \u001b[38;5;66;03m# datos = puerto_serie.readline().decode().strip()  # Leer datos de la UART\u001b[39;00m\n\u001b[0;32m     41\u001b[0m     \u001b[38;5;66;03m# print(datos, end='\\r')\u001b[39;00m\n\u001b[1;32m---> 43\u001b[0m     prediccion \u001b[38;5;241m=\u001b[39m \u001b[43mpredice\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdatos\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     44\u001b[0m     \u001b[38;5;28mprint\u001b[39m(prediccion)\n\u001b[0;32m     46\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m0.001\u001b[39m)\n",
      "Cell \u001b[1;32mIn[59], line 26\u001b[0m, in \u001b[0;36mpredice\u001b[1;34m(datos)\u001b[0m\n\u001b[0;32m     24\u001b[0m datos \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(datos)\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m modelo \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m---> 26\u001b[0m     prediccion \u001b[38;5;241m=\u001b[39m \u001b[43mmodelo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdatos\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     27\u001b[0m     prediccion\u001b[38;5;241m.\u001b[39mappend(datos)\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_file8ycih1em.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__predict_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"C:\\Users\\fraja\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training.py\", line 2137, in predict_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\fraja\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training.py\", line 2123, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\fraja\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training.py\", line 2111, in run_step  **\n        outputs = model.predict_step(data)\n    File \"C:\\Users\\fraja\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training.py\", line 2079, in predict_step\n        return self(x, training=False)\n    File \"C:\\Users\\fraja\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\fraja\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\input_spec.py\", line 250, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Exception encountered when calling layer 'sequential_44' (type Sequential).\n    \n    Input 0 of layer \"dense_72\" is incompatible with the layer: expected min_ndim=2, found ndim=1. Full shape received: (None,)\n    \n    Call arguments received by layer 'sequential_44' (type Sequential):\n      • inputs=tf.Tensor(shape=(None,), dtype=float32)\n      • training=False\n      • mask=None\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "import numpy as np\n",
    "import serial\n",
    "import time\n",
    "\n",
    "modelo = None  # Inicializa modelo como None\n",
    "\n",
    "def config_puerto_serie():\n",
    "    puerto_serie = serial.Serial('COM5', 115200, xonxoff=True)    # Configurar la comunicación serie\n",
    "    time.sleep(2)     # Esperar un tiempo para que la comunicación se establezca correctamente\n",
    "    return puerto_serie\n",
    "\n",
    "def carga_modelo():\n",
    "    global modelo  # Indica que se utilizará la variable global 'modelo' dentro de esta función\n",
    "    try:\n",
    "        modelo = load_model(\"modelo_3_precision_99,906_porc_sigmoid_2_neuronas_intermedia.h5\")\n",
    "        print(\"Modelo cargado correctamente\")\n",
    "        print(modelo)  # Imprime el modelo para verificar que se haya cargado correctamente\n",
    "    except Exception as e:\n",
    "        print(\"Error al cargar el modelo:\", e)\n",
    "\n",
    "def predice(datos):\n",
    "    prediccion = []\n",
    "    datos = np.array(datos)\n",
    "    if modelo is not None:\n",
    "        prediccion = modelo.predict(datos)\n",
    "        prediccion.append(datos)\n",
    "    else:\n",
    "        print(\"Error: El modelo no ha sido cargado correctamente\")\n",
    "    return prediccion\n",
    "\n",
    "def main():\n",
    "    # puerto_serie = config_puerto_serie()\n",
    "    carga_modelo()\n",
    "    \n",
    "    datos = [0.99993896,0.01214600,-0.00439453,0.00000000]\n",
    "    cont = 0\n",
    "    print()\n",
    "    while cont<50:\n",
    "        # datos = puerto_serie.readline().decode().strip()  # Leer datos de la UART\n",
    "        # print(datos, end='\\r')\n",
    "\n",
    "        prediccion = predice(datos)\n",
    "        print(prediccion)\n",
    "\n",
    "        time.sleep(0.001)\n",
    "        cont+=1\n",
    "\n",
    "    # puerto_serie.close()    # Cerrar el puerto serie\n",
    "\n",
    "main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "import numpy as np\n",
    "import serial\n",
    "import time\n",
    "\n",
    "modelo = None  # Inicializa modelo como None\n",
    "\n",
    "def config_puerto_serie():\n",
    "    puerto_serie = serial.Serial('COM5', 115200, xonxoff=True)    # Configurar la comunicación serie\n",
    "    time.sleep(2)     # Esperar un tiempo para que la comunicación se establezca correctamente\n",
    "    return puerto_serie\n",
    "\n",
    "def carga_modelo():\n",
    "    global modelo  # Indica que se utilizará la variable global 'modelo' dentro de esta función\n",
    "    try:\n",
    "        modelo = load_model(\"modelo_3_precision_99,906_porc_sigmoid_2_neuronas_intermedia.h5\")\n",
    "        print(\"Modelo cargado correctamente\")\n",
    "        print(modelo)  # Imprime el modelo para verificar que se haya cargado correctamente\n",
    "    except Exception as e:\n",
    "        print(\"Error al cargar el modelo:\", e)\n",
    "\n",
    "def predice(datos):\n",
    "    prediccion = []\n",
    "    datos = np.array(datos)\n",
    "    datos = np.expand_dims(datos, axis=0)  # Agregar una dimensión adicional para representar el lote de datos\n",
    "    if modelo is not None:\n",
    "        prediccion_modelo = modelo.predict(datos)\n",
    "        prediccion = np.hstack((datos, prediccion_modelo))  # Concatenar horizontalmente los datos originales y la predicción del modelo\n",
    "    else:\n",
    "        print(\"Error: El modelo no ha sido cargado correctamente\")\n",
    "    return prediccion\n",
    "\n",
    "def parsea(pred):\n",
    "    prediccion = pred[0][4:]\n",
    "    prediccion = list(prediccion)\n",
    "    posicion = prediccion.index(max(prediccion))\n",
    "    print(f\"El gesto es el tipo {posicion}\")\n",
    "\n",
    "def main():\n",
    "    puerto_serie = config_puerto_serie()\n",
    "    carga_modelo()\n",
    "    \n",
    "    cont = 0\n",
    "    print()\n",
    "    while cont<50:\n",
    "        datos = puerto_serie.readline().decode().strip()  # Leer datos de la UART\n",
    "        print(datos, end='\\r')\n",
    "\n",
    "        prediccion = predice(datos)\n",
    "        print(prediccion)\n",
    "\n",
    "        time.sleep(0.001)\n",
    "        cont+=1\n",
    "    puerto_serie.close()    # Cerrar el puerto serie\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo cargado correctamente\n",
      "<keras.engine.sequential.Sequential object at 0x00000262661650C0>\n",
      "\n",
      "0.99914551,-0.03527832,-0.02081299,0.00000000\n",
      "[0.99914551, -0.03527832, -0.02081299, 0.0]\n",
      "WARNING:tensorflow:5 out of the last 20 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000262661E16C0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 94ms/step\n",
      "El gesto es el tipo 0\n",
      "\n",
      "0.99914551,-0.03527832,-0.02081299,0.00000000\n",
      "[0.99914551, -0.03527832, -0.02081299, 0.0]\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "El gesto es el tipo 0\n",
      "\n",
      "0.99914551,-0.03527832,-0.02081299,0.00000000\n",
      "[0.99914551, -0.03527832, -0.02081299, 0.0]\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "El gesto es el tipo 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "import numpy as np\n",
    "import serial\n",
    "import time\n",
    "\n",
    "modelo = None  # Inicializa modelo como None\n",
    "\n",
    "def config_puerto_serie():\n",
    "    puerto_serie = serial.Serial('COM5', 115200, xonxoff=True)    # Configurar la comunicación serie\n",
    "    time.sleep(2)     # Esperar un tiempo para que la comunicación se establezca correctamente\n",
    "    return puerto_serie\n",
    "\n",
    "def carga_modelo():\n",
    "    global modelo  # Indica que se utilizará la variable global 'modelo' dentro de esta función\n",
    "    try:\n",
    "        modelo = load_model(\"modelo_3_precision_99,906_porc_sigmoid_2_neuronas_intermedia.h5\")\n",
    "        print(\"Modelo cargado correctamente\")\n",
    "        print(modelo)  # Imprime el modelo para verificar que se haya cargado correctamente\n",
    "    except Exception as e:\n",
    "        print(\"Error al cargar el modelo:\", e)\n",
    "\n",
    "def predice(datos):\n",
    "    prediccion = []\n",
    "    if modelo is not None:\n",
    "        prediccion_modelo = modelo.predict(datos)\n",
    "        prediccion = np.hstack((datos, prediccion_modelo))  # Concatenar horizontalmente los datos originales y la predicción del modelo\n",
    "    else:\n",
    "        print(\"Error: El modelo no ha sido cargado correctamente\")\n",
    "    return prediccion\n",
    "\n",
    "def parsea(pred):\n",
    "    prediccion = pred[0][4:]\n",
    "    prediccion = list(prediccion)\n",
    "    posicion = prediccion.index(max(prediccion))\n",
    "    print(f\"El gesto es el tipo {posicion}\")\n",
    "\n",
    "def main():\n",
    "    puerto_serie = config_puerto_serie()\n",
    "    carga_modelo()\n",
    "    \n",
    "    cont = 0\n",
    "    print()\n",
    "    while cont<3:\n",
    "        datos = puerto_serie.readline().decode().strip()  # Leer datos de la UART\n",
    "        datos = datos.split(',')  # Suponiendo que los datos están separados por comas\n",
    "        datos = [float(dato) for dato in datos]  # Convertir los datos a números flotantes\n",
    "        print(datos)\n",
    "\n",
    "        prediccion = predice(datos)\n",
    "        parsea(prediccion)\n",
    "        print()\n",
    "\n",
    "        time.sleep(0.001)\n",
    "        cont+=1\n",
    "    puerto_serie.close()    # Cerrar el puerto serie\n",
    "\n",
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
